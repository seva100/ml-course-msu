{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Лабораторная работа 2. Метод ближайших соседей и решающие деревья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Севастопольский Артем Михайлович\n",
    "\n",
    "Группа: 317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import bisect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn import metrics, cross_validation, tree, ensemble\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from joblib import Parallel, delayed\n",
    "#from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все эксперименты в этой лабораторной работе предлагается проводить на данных соревнования Amazon Employee Access Challenge: https://www.kaggle.com/c/amazon-employee-access-challenge\n",
    "\n",
    "В данной задаче предлагается предсказать, будет ли одобрен запрос сотрудника на получение доступа к тому или иному ресурсу. Все признаки являются категориальными.\n",
    "\n",
    "Для удобства данные можно загрузить по ссылке: https://www.dropbox.com/s/q6fbs1vvhd5kvek/amazon.csv\n",
    "\n",
    "Сразу прочитаем данные и создадим разбиение на обучение и контроль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTION</th>\n",
       "      <th>RESOURCE</th>\n",
       "      <th>MGR_ID</th>\n",
       "      <th>ROLE_ROLLUP_1</th>\n",
       "      <th>ROLE_ROLLUP_2</th>\n",
       "      <th>ROLE_DEPTNAME</th>\n",
       "      <th>ROLE_TITLE</th>\n",
       "      <th>ROLE_FAMILY_DESC</th>\n",
       "      <th>ROLE_FAMILY</th>\n",
       "      <th>ROLE_CODE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>39353</td>\n",
       "      <td>85475</td>\n",
       "      <td>117961</td>\n",
       "      <td>118300</td>\n",
       "      <td>123472</td>\n",
       "      <td>117905</td>\n",
       "      <td>117906</td>\n",
       "      <td>290919</td>\n",
       "      <td>117908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17183</td>\n",
       "      <td>1540</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>123125</td>\n",
       "      <td>118536</td>\n",
       "      <td>118536</td>\n",
       "      <td>308574</td>\n",
       "      <td>118539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>36724</td>\n",
       "      <td>14457</td>\n",
       "      <td>118219</td>\n",
       "      <td>118220</td>\n",
       "      <td>117884</td>\n",
       "      <td>117879</td>\n",
       "      <td>267952</td>\n",
       "      <td>19721</td>\n",
       "      <td>117880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>36135</td>\n",
       "      <td>5396</td>\n",
       "      <td>117961</td>\n",
       "      <td>118343</td>\n",
       "      <td>119993</td>\n",
       "      <td>118321</td>\n",
       "      <td>240983</td>\n",
       "      <td>290919</td>\n",
       "      <td>118322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>42680</td>\n",
       "      <td>5905</td>\n",
       "      <td>117929</td>\n",
       "      <td>117930</td>\n",
       "      <td>119569</td>\n",
       "      <td>119323</td>\n",
       "      <td>123932</td>\n",
       "      <td>19793</td>\n",
       "      <td>119325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
       "0       1     39353   85475         117961         118300         123472   \n",
       "1       1     17183    1540         117961         118343         123125   \n",
       "2       1     36724   14457         118219         118220         117884   \n",
       "3       1     36135    5396         117961         118343         119993   \n",
       "4       1     42680    5905         117929         117930         119569   \n",
       "\n",
       "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
       "0      117905            117906       290919     117908  \n",
       "1      118536            118536       308574     118539  \n",
       "2      117879            267952        19721     117880  \n",
       "3      118321            240983       290919     118322  \n",
       "4      119323            123932        19793     119325  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('amazon.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32769, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94210992096188473"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# доля положительных примеров\n",
    "data.ACTION.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTION 2\n",
      "RESOURCE 7518\n",
      "MGR_ID 4243\n",
      "ROLE_ROLLUP_1 128\n",
      "ROLE_ROLLUP_2 177\n",
      "ROLE_DEPTNAME 449\n",
      "ROLE_TITLE 343\n",
      "ROLE_FAMILY_DESC 2358\n",
      "ROLE_FAMILY 67\n",
      "ROLE_CODE 343\n"
     ]
    }
   ],
   "source": [
    "# число значений у признаков\n",
    "for col_name in data.columns:\n",
    "    print col_name, len(data[col_name].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "# data is transformed to np.array in order to manipulate it faster\n",
    "data = data.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[:, 1:], data[:, 0],\n",
    "                                                    test_size=0.3, random_state=241)\n",
    "features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: kNN и категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Реализуйте три функции расстояния на категориальных признаках, которые обсуждались на втором семинаре. Реализуйте самостоятельно метод k ближайших соседей, который будет уметь работать с этими функциями расстояния. Подсчитайте для каждой из них качество на тестовой выборке `X_test` при числе соседей $k = 10$. Метрика качества — AUC-ROC.\n",
    "\n",
    "#### Какая функция расстояния оказалась лучшей?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CategoricalDistanceCounter(object):\n",
    "    def __init__(self, X_train):\n",
    "        self.objects, self.features = X_train.shape\n",
    "        self.counts = [pd.value_counts(X_train[:, i]) for i in xrange(X_train.shape[1])]\n",
    "        # `counts[i]` is a Series that shows how many times value `i` appears in col № i.\n",
    "        # `counts` depends on X_train.\n",
    "        self.counts_dict = [cnt.to_dict() for cnt in self.counts]\n",
    "        self.prob = [(cnt / len(X_train)).sort_values(inplace=False).to_dict() \n",
    "                     for cnt in self.counts]\n",
    "        self.prob_vals = map(lambda d: np.array(d.values()), self.prob)\n",
    "        self.prob_hit = [cnt * (cnt - 1) / self.objects / (self.objects - 1) \n",
    "                         for cnt in self.counts]\n",
    "        # `prob_hit` is estimate of probability that two objects have the same feature value.\n",
    "        self.prob_hit_cumsum = [np.hstack(([0], np.array(ar).cumsum()))\n",
    "                                for ar in self.prob_hit]\n",
    "    \n",
    "\n",
    "#@jit\n",
    "def dist(p, q, cntr, weights=None, dist_type=None):\n",
    "    '''Accepts dist_type=1, 2 or 3.\n",
    "    p, q and weights should be numpy vectors of the same length.\n",
    "    '''\n",
    "    dist = None\n",
    "    if dist_type == 1:\n",
    "        diff = (p != q).astype(int)\n",
    "    elif dist_type == 2:\n",
    "        p_prob = np.empty(cntr.features)\n",
    "        for i in xrange(cntr.features):\n",
    "            p_prob[i] = cntr.prob[i].get(p[i], 0)\n",
    "        last_pos = np.empty(cntr.features)\n",
    "        for i in xrange(cntr.features):\n",
    "            last_pos[i] = bisect.bisect_right(cntr.prob_vals[i], p_prob[i])\n",
    "        appr_prob = np.empty(cntr.features)\n",
    "        for i in xrange(cntr.features):\n",
    "            appr_prob[i] = cntr.prob_hit_cumsum[i][last_pos[i]]\n",
    "        diff = np.where(p != q, 1, appr_prob)\n",
    "        #p_prob = [cntr.prob[i].get(p[i], 0)\n",
    "        #          for i in range(cntr.features)]\n",
    "        #last_pos = [bisect.bisect_right(cntr.prob_vals[i], p_prob[i])\n",
    "        #            for i in range(cntr.features)]\n",
    "        #appr_prob = [cntr.prob_hit_cumsum[i][last_pos[i]]\n",
    "        #             for i in range(cntr.features)]\n",
    "        \n",
    "    elif dist_type == 3:\n",
    "        p_cnt = np.empty(cntr.features)\n",
    "        q_cnt = np.empty(cntr.features)\n",
    "        for i in xrange(cntr.features):\n",
    "            p_cnt[i] = cntr.counts_dict[i].get(p[i], 0)\n",
    "            q_cnt[i] = cntr.counts_dict[i].get(q[i], 0)\n",
    "            # Taking care of possible troubles with logarithm.\n",
    "            if p_cnt[i] == 0:\n",
    "                p_cnt[i] = 1\n",
    "            if q_cnt[i] == 0:\n",
    "                q_cnt[i] = 1\n",
    "        diff = (p != q).astype(int) * np.log(p_cnt) * np.log(q_cnt)\n",
    "        #diff = (p != q).astype(int) * np.log([cntr.counts_dict[i].get(p[i], 0)\n",
    "        #                                      for i in range(cntr.features)]) * \\\n",
    "        #    np.log([cntr.counts_dict[i].get(q[i], 0)\n",
    "        #            for i in range(cntr.features)])\n",
    "    else:\n",
    "        raise Exception('Wrong metric')\n",
    "    \n",
    "    dist = np.sum(weights * diff)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def knn_predict(y_train, knn_idx, n_classes, K):\n",
    "    '''Makes prediction by KNN method given matrix of distances from X_test to its neighbors.\n",
    "    \n",
    "    y_train: vector of answers for train set.\n",
    "    knn_idx: 2D array that stores indices of K nearest neighbors \n",
    "    for each point of test set.\n",
    "    n_classes: number of classes.\n",
    "    K: number of neighbors.\n",
    "    '''\n",
    "    \n",
    "    n_test_samples = knn_idx.shape[0]\n",
    "    all_knn_idx = knn_idx[:, :K].ravel()\n",
    "    all_knn_classes = y_train[all_knn_idx]\n",
    "    knn_classes = all_knn_classes.reshape(n_test_samples, K)\n",
    "    \n",
    "    votes = np.empty((n_test_samples, n_classes))\n",
    "    for cls in range(n_classes):\n",
    "        votes[:, cls] = np.sum(knn_classes == cls, axis=1)\n",
    "    y_pred = np.argmax(votes, axis=1)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def pdist(X_test, X_train, func):\n",
    "    ans = np.empty((X_test.shape[0], X_train.shape[0]))\n",
    "    for i in xrange(X_test.shape[0]):\n",
    "        #print i,\n",
    "        for j in xrange(X_train.shape[0]):\n",
    "            ans[i, j] = func(X_test[i], X_train[j])\n",
    "    print \"pdist for chunk build.\"\n",
    "    return ans\n",
    "\n",
    "#@jit\n",
    "def pdist_chunked(X_test, X_train, func, chunk_size=1000):\n",
    "    ans = np.empty((X_test.shape[0], X_train.shape[0]))\n",
    "    for i in range(0, X_test.shape[0], chunk_size):\n",
    "        chunk = X_test[i:i + chunk_size]\n",
    "        chunk_ans = pdist(chunk, X_train, func)\n",
    "        ans[i:i + chunk_size] = chunk_ans\n",
    "    return ans\n",
    "\n",
    "#@jit\n",
    "def pdist_for_chunk(func, start_idx, end_idx):\n",
    "    ans = np.empty((end_idx - start_idx, nX_train.shape[0]))\n",
    "    for i in xrange(start_idx, end_idx):\n",
    "        #print i,\n",
    "        for j in xrange(nX_train.shape[0]):\n",
    "            ans[i - start_idx, j] = func(nX_test[i], nX_train[j])\n",
    "    return ans\n",
    "\n",
    "def pdist_parallel(func, n_samples=-1, chunk_size=1000,\n",
    "                  n_jobs=1):\n",
    "    if n_samples == -1:\n",
    "        n_samples = nX_test.shape[0]\n",
    "    \n",
    "    ans = np.empty((n_samples, nX_train.shape[0]))\n",
    "    with Parallel(n_jobs=n_jobs, verbose=1) as prl:\n",
    "        chunk_ans = prl(delayed(pdist_for_chunk)(func, i, min(i + chunk_size, n_samples))\n",
    "                        for i in range(0, n_samples, chunk_size))\n",
    "    for i in range(0, n_samples, chunk_size):\n",
    "        ans[i:i + chunk_size] = chunk_ans[i / chunk_size]\n",
    "    return ans\n",
    "\n",
    "#@jit\n",
    "def get_knn_idx(pw_dist, K):\n",
    "    '''Returns indices of K nearest neighbors\n",
    "    '''\n",
    "    return np.argpartition(pw_dist, K)[:, :K]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #1. Preparing distance matrix...\n",
      "prediction mean:  0.972942732174\n",
      "AUC-ROC score:  0.627809964051\n",
      "Metric #2. Preparing distance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=19)]: Done  20 out of  20 | elapsed:  7.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction mean:  0.974265079849\n",
      "AUC-ROC score:  0.626747601395\n",
      "Metric #3. Preparing distance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=19)]: Done  20 out of  20 | elapsed: 34.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction mean:  0.975892584681\n",
      "AUC-ROC score:  0.617014084325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=19)]: Done  20 out of  20 | elapsed: 21.9min finished\n"
     ]
    }
   ],
   "source": [
    "dist_cntr = CategoricalDistanceCounter(X_train)\n",
    "y_pred = []\n",
    "for d in range(1, 4):\n",
    "    print \"Metric #{}. Preparing distance matrix...\".format(d)\n",
    "    #pairwise_dist = cdist(X_test, X_train, \n",
    "    #                      partial(dist_cntr.dist, weights=np.ones(features), dist_type=d))\n",
    "    #pairwise_dist = pdist(X_test, X_train, \n",
    "    #                      partial(dist, cntr=dist_cntr, weights=np.ones(features), dist_type=d))\n",
    "    \n",
    "    nX_train, nX_test = X_train, X_test\n",
    "    pairwise_dist = pdist_parallel(partial(dist, cntr=dist_cntr, weights=np.ones(features), dist_type=d),\n",
    "                          n_samples=-1, chunk_size=500, n_jobs=19)\n",
    "    knn_idx = get_knn_idx(pairwise_dist, 10)\n",
    "    y_pred.append(knn_predict(y_train, knn_idx, 2, 10))\n",
    "    \n",
    "    print \"prediction mean: \", y_pred[-1].mean()\n",
    "    score = roc_auc_score(y_test, y_pred[-1])\n",
    "    print \"AUC-ROC score: \", score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 (бонус). Подберите лучшее (на тестовой выборке) число соседей $k$ для каждой из функций расстояния. Какое наилучшее качество удалось достичь?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def knn_accuracy(y_train, y_test, pw_dist, K_opts):\n",
    "    '''Calculates accuracy of KNN method on X_test.\n",
    "    It runs KNN multiple times for all provided K_opts.\n",
    "    \n",
    "    K_opts: array_like of options for choosing K.\n",
    "    '''\n",
    "    # DataFrame for results\n",
    "    acc = pd.DataFrame(index=K_opts)\n",
    "    K_max = max(K_opts)\n",
    "    knn_idx = get_knn_idx(pw_dist, K_max)\n",
    "    \n",
    "    for K in K_opts:\n",
    "        print \"Running KNN for K={}\".format(K)\n",
    "        y_pred = knn_predict(y_train, knn_idx, 2, K)\n",
    "        cur_acc = roc_auc_score(y_test, y_pred)\n",
    "        acc.ix[K, 'Accuracy'] = cur_acc\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric #1. Preparing distance matrix...\n",
      "Computing accuracy...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.571555\n",
      "4    0.541972\n",
      "8    0.524312\n",
      "16   0.509517\n",
      "32   0.506633\n",
      "64   0.500000\n",
      "128  0.500000\n",
      "Best K: 2.0, AUC-ROC score: 0.57155461315\n",
      "Metric #2. Preparing distance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed:  3.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.561035\n",
      "4    0.541798\n",
      "8    0.528637\n",
      "16   0.518096\n",
      "32   0.511446\n",
      "64   0.500829\n",
      "128  0.500000\n",
      "Best K: 2.0, AUC-ROC score: 0.561034500234\n",
      "Metric #3. Preparing distance matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed: 21.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing accuracy...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.565501\n",
      "4    0.536189\n",
      "8    0.519392\n",
      "16   0.509571\n",
      "32   0.503154\n",
      "64   0.500000\n",
      "128  0.500000\n",
      "Best K: 2.0, AUC-ROC score: 0.565500682543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed: 14.2min finished\n"
     ]
    }
   ],
   "source": [
    "K_opts = np.full((7,), 2, dtype=float).cumprod()    # K_opts is powers of two: [2, 4, 8, 16, ..., 128]\n",
    "dist_cntr = CategoricalDistanceCounter(X_train)\n",
    "for d in range(1, 4):\n",
    "    print \"Metric #{}. Preparing distance matrix...\".format(d)\n",
    "    #pairwise_dist = cdist(X_test, X_train, \n",
    "    #                      partial(dist_cntr.dist, weights=np.ones(features), dist_type=d))\n",
    "    nX_train, nX_test = X_train, X_test\n",
    "    pairwise_dist = pdist_parallel(partial(dist, cntr=dist_cntr, weights=np.ones(features), dist_type=d),\n",
    "                          n_samples=-1, chunk_size=900, n_jobs=11)\n",
    "    print \"Computing accuracy...\"\n",
    "    acc = knn_accuracy(y_train, y_test, pairwise_dist, K_opts)\n",
    "    print(acc)\n",
    "    print \"Best K: {}, AUC-ROC score: {}\".format(acc.idxmax()[0], acc.max()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Реализуйте счетчики (http://blogs.technet.com/b/machinelearning/archive/2015/02/17/big-learning-made-easy-with-counts.aspx), которые заменят категориальные признаки на вещественные.\n",
    "\n",
    "А именно, каждый категориальный признак нужно заменить на три: \n",
    "1. Число `counts` объектов в обучающей выборке с таким же значением признака.\n",
    "2. Число `clicks` объектов первого класса ($y = 1$) в обучающей выборке с таким же значением признака.\n",
    "3. Сглаженное отношение двух предыдущих величин: (`clicks` + 1) / (`counts` + 2).\n",
    "\n",
    "Поскольку признаки, содержащие информацию о целевой переменной, могут привести к переобучению, может оказаться полезным сделать *фолдинг*: разбить обучающую выборку на $n$ частей, и для $i$-й части считать `counts` и `clicks` по всем остальным частям. Для тестовой выборки используются счетчики, посчитанный по всей обучающей выборке. Реализуйте и такой вариант. Можно использовать $n = 3$.\n",
    "\n",
    "#### Посчитайте на тесте AUC-ROC метода $k$ ближайших соседей с евклидовой метрикой для выборки, где категориальные признаки заменены на счетчики. Сравните по AUC-ROC два варианта формирования выборки — с фолдингом и без. Не забудьте подобрать наилучшее число соседей $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def counts(X_train, y_train, X_test):\n",
    "    smooth_X_test = np.full_like(X_test, 0.5, dtype=float)\n",
    "    counts = np.empty((X_test.shape[0],))\n",
    "    clicks = np.empty((X_test.shape[0],))\n",
    "    for col in xrange(features):\n",
    "        vc = pd.value_counts(X_train[:, col])\n",
    "        vc_dict = vc.to_dict()\n",
    "        \n",
    "        for i in xrange(X_test.shape[0]):\n",
    "            counts[i] = vc_dict.get(X_test[i, col], 0)\n",
    "        #counts = map(lambda el: vc.get(el, 0), X_test[col])\n",
    "        \n",
    "        vc_pos = pd.value_counts(X_train[y_train == 1, col])\n",
    "        vc_pos_dict = vc_pos.to_dict()\n",
    "        \n",
    "        for i in xrange(X_test.shape[0]):\n",
    "            clicks[i] = vc_pos_dict.get(X_test[i, col], 0)\n",
    "        #clicks = map(lambda el: vc_pos.get(el, 0), X_test[col])\n",
    "        \n",
    "        smooth_X_test[:, col] = (clicks + 1).astype(float) / (counts + 2)\n",
    "    \n",
    "    return smooth_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing distance matrix...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.639422\n",
      "4    0.633487\n",
      "8    0.616911\n",
      "16   0.620438\n",
      "32   0.609793\n",
      "64   0.609906\n",
      "128  0.603673\n",
      "\n",
      "[7 rows x 1 columns]\n",
      "Best K: 2.0, AUC-ROC score for counts without folding: 0.639422091968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=18)]: Done  20 out of  20 | elapsed:  5.3min finished\n"
     ]
    }
   ],
   "source": [
    "# Without folding.\n",
    "smooth_X_train = counts(X_train, y_train, X_train)\n",
    "smooth_X_test = counts(X_train, y_train, X_test)\n",
    "print \"Preparing distance matrix...\"\n",
    "#pairwise_dist = cdist(smooth_X_train, smooth_X_test, metric='euclidean')\n",
    "def euclid_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "\n",
    "nX_train, nX_test = smooth_X_train, smooth_X_test\n",
    "pairwise_dist = pdist_parallel(euclid_dist,\n",
    "                               n_samples=-1, chunk_size=500, n_jobs=18)\n",
    "\n",
    "K_opts = np.full((7,), 2).cumprod()    # K_opts is powers of two: [2, 4, 8, 16, ..., 128]\n",
    "acc = knn_accuracy(y_train, y_test, pairwise_dist, K_opts)\n",
    "print(acc)\n",
    "print \"Best K: {}, AUC-ROC score for counts without folding: {}\".format(acc.idxmax()[0], acc.max()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def counts_folded(X_train, y_train, X_test, n_folds=3):\n",
    "    print \"Preparing folded data set with counts...\"\n",
    "    # We can use simple KFold:\n",
    "    #kf = cross_validation.KFold(n=X_train.shape[0], n_folds=n_folds, shuffle=True, random_state=243)\n",
    "    # or stratified KFold:\n",
    "    cv = cross_validation.StratifiedKFold(y_train, n_folds=n_folds, \n",
    "                                          shuffle=True, random_state=243)\n",
    "    \n",
    "    fold_no = 0\n",
    "    smooth_X_train = np.full_like(X_train, 0.5, dtype=float)\n",
    "    for fold_index, rest_index in cv:\n",
    "        # For fold of train set, counts and clicks are counted based on other parts.\n",
    "        # For test set, counts and clicks are counted based on a whole train set.\n",
    "        Xt_fold, Xt_rest = X_train[fold_index, :], X_train[rest_index, :]\n",
    "        yt_rest = y_train[rest_index]\n",
    "        smooth_Xt_fold = counts(Xt_rest, yt_rest, Xt_fold)\n",
    "        smooth_X_train[fold_index, :] = smooth_Xt_fold\n",
    "    \n",
    "    smooth_X_test = counts(X_train, y_train, X_test)\n",
    "    return smooth_X_train, smooth_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing folded data set with counts...\n",
      "Preparing distance matrix...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.572065\n",
      "4    0.532453\n",
      "8    0.518204\n",
      "16   0.509679\n",
      "32   0.508129\n",
      "64   0.504146\n",
      "128  0.502488\n",
      "\n",
      "[7 rows x 1 columns]\n",
      "Best K: 2.0, AUC-ROC score for counts without folding: 0.572064633486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=18)]: Done  20 out of  20 | elapsed:  6.7min finished\n"
     ]
    }
   ],
   "source": [
    "# With folding.\n",
    "smooth_X_train, smooth_X_test = counts_folded(X_train, y_train, X_test)\n",
    "print \"Preparing distance matrix...\"\n",
    "def euclid_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "nX_train, nX_test = smooth_X_train, smooth_X_test\n",
    "#pairwise_dist = cdist(nX_test[:100], nX_train, 'euclidean')\n",
    "pairwise_dist = pdist_parallel(euclid_dist,\n",
    "                               n_samples=-1, chunk_size=500, n_jobs=18)\n",
    "\n",
    "K_opts = np.full((7,), 2).cumprod()    # K_opts is powers of two: [2, 4, 8, 16, ..., 128]\n",
    "acc = knn_accuracy(y_train, y_test, pairwise_dist, K_opts)\n",
    "print(acc)\n",
    "print \"Best K: {}, AUC-ROC score for counts without folding: {}\".format(acc.idxmax()[0], acc.max()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Добавьте в исходную выборку парные признаки — то есть для каждой пары $f_i$, $f_j$ исходных категориальных признаков добавьте новый категориальный признак $f_{ij}$, значение которого является конкатенацией значений $f_i$ и $f_j$. Посчитайте счетчики для этой выборки, найдите качество метода $k$ ближайших соседей с наилучшим $k$ (с фолдингом и без)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#@jit\n",
    "def paired(X):\n",
    "    new_X = np.empty((X.shape[0], X.shape[1] + X.shape[1] * (X.shape[1] - 1) / 2), dtype=int)\n",
    "    col_no = 0\n",
    "    new_X[:, :features] = X.copy()\n",
    "    for i in xrange(features):\n",
    "        for j in xrange(i + 1, features):\n",
    "            for k in xrange(X.shape[0]):\n",
    "                new_X[k, features + col_no] = int(str(X[k, i]) + str(X[k, j]))\n",
    "            col_no += 1\n",
    "    return new_X\n",
    "\n",
    "Xp_train = paired(X_train)\n",
    "Xp_test = paired(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing distance matrix...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.639422\n",
      "4    0.633487\n",
      "8    0.616911\n",
      "16   0.620438\n",
      "32   0.609793\n",
      "64   0.609906\n",
      "128  0.603673\n",
      "\n",
      "[7 rows x 1 columns]\n",
      "Best K: 2.0, AUC-ROC score for counts without folding: 0.639422091968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "# Without folding.\n",
    "smooth_Xp_train = counts(Xp_train, y_train, Xp_train)\n",
    "smooth_Xp_test = counts(Xp_train, y_train, Xp_test)\n",
    "print \"Preparing distance matrix...\"\n",
    "def euclid_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "nX_train, nX_test = smooth_Xp_train, smooth_Xp_test\n",
    "pairwise_dist = pdist_parallel(euclid_dist,\n",
    "                               n_samples=-1, chunk_size=900, n_jobs=11)\n",
    "\n",
    "K_opts = np.full((7,), 2).cumprod()    # K_opts is powers of two: [2, 4, 8, 16, ..., 128]\n",
    "acc = knn_accuracy(y_train, y_test, pairwise_dist, K_opts)\n",
    "print(acc)\n",
    "print \"Best K: {}, AUC-ROC score for counts without folding: {}\".format(acc.idxmax()[0], acc.max()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing folded data set with counts...\n",
      "Preparing distance matrix...\n",
      "Running KNN for K=2.0\n",
      "Running KNN for K=4.0\n",
      "Running KNN for K=8.0\n",
      "Running KNN for K=16.0\n",
      "Running KNN for K=32.0\n",
      "Running KNN for K=64.0\n",
      "Running KNN for K=128.0\n",
      "     Accuracy\n",
      "2    0.572065\n",
      "4    0.532453\n",
      "8    0.518204\n",
      "16   0.509679\n",
      "32   0.508129\n",
      "64   0.504146\n",
      "128  0.502488\n",
      "\n",
      "[7 rows x 1 columns]\n",
      "Best K: 2.0, AUC-ROC score for counts without folding: 0.572064633486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Done  11 out of  11 | elapsed:  4.1min finished\n"
     ]
    }
   ],
   "source": [
    "# With folding.\n",
    "smooth_Xpf_train, smooth_Xpf_test = counts_folded(Xp_train, y_train, Xp_test)\n",
    "print \"Preparing distance matrix...\"\n",
    "def euclid_dist(a, b):\n",
    "    return np.linalg.norm(a - b)\n",
    "nX_train, nX_test = smooth_Xpf_train, smooth_Xpf_test\n",
    "pairwise_dist = pdist_parallel(euclid_dist,\n",
    "                               n_samples=-1, chunk_size=900, n_jobs=11)\n",
    "\n",
    "K_opts = np.full((7,), 2).cumprod()    # K_opts is powers of two: [2, 4, 8, 16, ..., 128]\n",
    "acc = knn_accuracy(y_train, y_test, pairwise_dist, K_opts)\n",
    "print(acc)\n",
    "print \"Best K: {}, AUC-ROC score for counts without folding: {}\".format(acc.idxmax()[0], acc.max()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Решающие деревья и леса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Возьмите из предыдущей части выборку с парными признаками, преобразованную с помощью счетчиков без фолдинга. Настройте решающее дерево, подобрав оптимальные значения параметров `max_depth` и `min_samples_leaf`. Какой наилучший AUC-ROC на контроле удалось получить?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Decision Tree:  0.651982016661\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(max_depth=1000, min_samples_leaf=6, random_state=243)\n",
    "clf.fit(smooth_Xp_train, y_train)\n",
    "yp_pred = clf.predict(smooth_Xp_test)\n",
    "print \"Score on Decision Tree: \", roc_auc_score(y_test, yp_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Настройте случайный лес, подобрав оптимальное число деревьев `n_estimators`. Какое качество на тестовой выборке он дает?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Random Forest:  0.684697718602\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=400, random_state=243,\n",
    "                                     n_jobs=11)\n",
    "clf.fit(smooth_Xp_train, y_train)\n",
    "y_pred = clf.predict(smooth_Xp_test)\n",
    "print \"Score on Random Forest: \", roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Возьмите выборку с парными признаками, для которой счетчики посчитаны с фолдингом. Обучите на ней случайный лес, подобрав число деревьев. Какое качество на тестовой выборке он дает? Чем вы можете объяснить изменение результата по сравнению с предыдущим пунктом?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Random Forest using set of counts:  0.523396239436\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=50000, random_state=243,\n",
    "                                     n_jobs=11)\n",
    "clf.fit(smooth_Xpf_train, y_train)\n",
    "y_pred_c = clf.predict(smooth_Xpf_test)\n",
    "print \"Score on Random Forest using set of counts: \", roc_auc_score(y_test, y_pred_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Результат для выборки с парными признаками, к которым применены счетчики **с фолдингом**, оказался **ниже**. \n",
    "\n",
    "Возможные причины:\n",
    "- при подсчете с фолдингом при обработке очередного фолда не учитываются данные из этого фолда, а это может быть важно. Кроме того, классы не сбалансированы: элементов класса 0 &mdash; 5%, класса 1 &mdash; 95% (см. выше). Поэтому при потере трети выборки могут теряться данные о закономерностях, дающих объекту метку \"0\".\n",
    "- так как решающие деревья и случайные леса склонны к переобучению, то возможно, что оно возникает и здесь (на каждом фолде случайный лес слишком настраивается на закономерности из других фолдов).\n",
    "- из-за того, что при фолдинге значения признаков считались независимо, признаки имеют немного разный смысл, и, возможно, из-за этого алгоритм не может выделить для них общие закономерности. К тому же, на фолдах обучающей выборки и на тестовой выборке счетчики вычисляются по разным размерам выборок."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
